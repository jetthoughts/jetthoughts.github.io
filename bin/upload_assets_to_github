#!/usr/bin/env ruby

require 'fileutils'
require 'net/http'
require 'uri'
require 'cgi'

IMG_REGEX = %r{!\[(?<alt>(?:[^\[\]]|\[(?:[^\[\]]|\[[^\[\]]*\])*\])*)\]\((?<url>https?:\/\/[^\s\)]+)\)}

BLOG_DIR = 'content/blog'
REPO_URL = 'https://raw.githubusercontent.com/jetthoughts/jetthoughts.github.io/master'

class ImageDownloader
  def download(url, dest)
    max_attempts = 5
    attempts = 0

    begin
      uri = URI(url)
      Net::HTTP.start(uri.host, uri.port, use_ssl: uri.scheme == 'https', open_timeout: 20, read_timeout: 60) do |http|
        request = Net::HTTP::Get.new(uri)
        http.request(request) do |response|
          if response.is_a?(Net::HTTPSuccess)
            File.open(dest, 'wb') do |io|
              response.read_body { |chunk| io.write(chunk) }
            end
          else
            puts "Failed to download #{url}: #{response.code} #{response.message}"
            return false
          end
        end
      end
    rescue Exception => e
      attempts += 1
      puts "Attempt #{attempts} of #{max_attempts} failed with message: #{e.message}"
      retry if attempts < max_attempts
    end

    true
  end

  def remove_cdn(url)
    if url.include?('cdn-cgi')
      decoded_url = URI.decode_www_form_component(url.split('/https%3A').last)
      'https:' + decoded_url
    else
      url
    end
  end
end

class BlogProcessor
  def initialize(downloader)
    @downloader = downloader
  end

  def process_blogs
    Dir.glob("#{BLOG_DIR}/*/index.md").each do |file_path|
      process_blog(file_path)
    end
  end

  private

  def process_blog(file_path)
    file_name = File.basename(File.dirname(file_path))
    content = File.read(file_path)

    # Process cover image if it exists
    content = process_cover_image(file_name, content, file_path)

    # Process images in the blog content
    content = process_images(file_name, content)

    File.write(file_path, content)
  end

  def process_cover_image(file_name, content, file_path)
    cover_image_match = content.match(/cover_image: "(?<url>http[^\s\)]*)"/)

    if cover_image_match
      cover_image_url = cover_image_match[:url]
      cover_image_url = @downloader.remove_cdn(cover_image_url) # Remove CDN part
      ext = File.extname(URI(cover_image_url).path)

      cover_path = "#{BLOG_DIR}/#{file_name}/cover#{ext}"

      FileUtils.mkdir_p(File.dirname(cover_path))
      # Only proceed if the download is successful
      if @downloader.download(cover_image_url, cover_path)
        updated_content = content.sub(cover_image_url, REPO_URL + "/" + cover_path)

        File.write(file_path, updated_content)

        return updated_content
      else
        FileUtils.rm_f(cover_path) # Remove the file if the download was unsuccessful
      end
    end

    content
  end

  def process_images(file_name, content)
    index = 0
    new_content = content.gsub(IMG_REGEX) do |match|
      alt_text = $~[:alt]
      img_url = $~[:url]
      img_url = @downloader.remove_cdn(img_url) # Remove CDN part
      ext = File.extname(URI(img_url).path)

      new_file = "file_#{index}#{ext}"
      new_path = "#{BLOG_DIR}/#{file_name}/#{new_file}"

      FileUtils.mkdir_p(File.dirname(new_path))
      if @downloader.download(img_url, new_path)
        replacement = "![#{alt_text}](#{new_file})"
        index += 1
        replacement
      else
        match
      end
    end
    new_content
  end
end

downloader = ImageDownloader.new
processor = BlogProcessor.new(downloader)
processor.process_blogs
