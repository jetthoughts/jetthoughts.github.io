---
Global Reference: /knowledge/60.01-global-agent-guidance-reference.md
Authority: Secondary (Extends Global Standards)
Last Synced: 2024-01-19
---

# TDD Quality Enforcement Standards

**ZERO-TOLERANCE QUALITY ENFORCEMENT FOR CONTENT AND CODE**

## ğŸš¨ **TEST MASKING PREVENTION SYSTEM**

### **Prohibited Test Anti-Patterns** (BLOCKED by bin/test)

The following patterns are AUTOMATICALLY REJECTED and will cause `bin/test` to fail:

```ruby
# âŒ VIOLATION: Test masking with output statements
def test_user_creation
  puts "Creating user..."           # BLOCKED - masks test intent
  user = User.new(name: "John")
  puts "User created: #{user.name}" # BLOCKED - not an assertion
  print "Test completed"            # BLOCKED - no validation
end

# âŒ VIOLATION: No assertions present
def test_data_processing
  data = { id: 1, name: "test" }
  process_data(data)               # BLOCKED - no verification
  # Missing any assert_*, refute_*, or flunk statements
end

# âŒ VIOLATION: False positive tests
def test_always_passes
  p "This test always passes"      # BLOCKED - inspection without validation
  true                            # BLOCKED - meaningless return
end
```

### **Required Test Patterns** (ENFORCED by bin/test)

Every test must follow these mandatory patterns:

```ruby
# âœ… CORRECT: Proper assertion-based validation
def test_user_creation_with_valid_data
  user = User.new(name: "John", email: "john@example.com")

  assert_equal "John", user.name              # REQUIRED - validates behavior
  assert_equal "john@example.com", user.email # REQUIRED - validates state
  assert_kind_of User, user                   # REQUIRED - validates type
end

# âœ… CORRECT: Error condition validation
def test_user_creation_with_invalid_data
  user = User.new(name: "", email: "invalid")

  refute user.valid?                          # REQUIRED - negative assertion
  assert_includes user.errors[:name], "can't be blank"
  assert_includes user.errors[:email], "is invalid"
end

# âœ… CORRECT: Explicit failure declaration
def test_upcoming_feature
  flunk "Feature not implemented yet - TDD red phase" # ACCEPTABLE
end

# âœ… CORRECT: Complex behavior validation
def test_user_authentication_process
  user = User.create!(name: "John", email: "john@example.com", password: "secure123")

  # Validate creation
  assert_persisted user
  assert user.authenticate("secure123")

  # Validate authentication failure
  refute user.authenticate("wrong_password")

  # Validate state changes
  user.lock_account!
  refute user.authenticate("secure123")
  assert user.account_locked?
end
```

## ğŸ“‹ **INTEGRATION WITH EXISTING TEST INFRASTRUCTURE**

### **bin/test Integration with Quality Standards**

The existing `bin/test` script is the primary enforcement mechanism:

```bash
#!/usr/bin/env sh
set -euo pipefail

if [ $# -eq 0 ]; then
  bundle exec rake test    # Runs ALL quality validations
else
  bundle exec ruby -Itest "$@"  # Runs specific test file
fi
```

**Quality Enforcement Flow**:
1. `bin/test` â†’ `bundle exec rake test` â†’ `Rakefile` â†’ `test/**/*_test.rb`
2. Minitest framework loads and executes all `*_test.rb` files
3. Each test method is validated for assertion presence
4. Output statements without assertions cause test failures
5. Missing assertions result in meaningless tests that get flagged

### **Minitest Assertion Methods (REQUIRED)**

Every test must use these assertion methods:

```ruby
# âœ… EQUALITY ASSERTIONS
assert_equal expected, actual          # Values must be equal
assert_same expected, actual           # Object identity must be same
refute_equal unexpected, actual        # Values must NOT be equal

# âœ… BOOLEAN ASSERTIONS
assert condition                       # Condition must be truthy
assert_predicate object, :method?      # Predicate method must return true
refute condition                       # Condition must be falsy
refute_predicate object, :method?      # Predicate method must return false

# âœ… COLLECTION ASSERTIONS
assert_includes collection, item       # Collection must contain item
assert_empty collection               # Collection must be empty
refute_empty collection               # Collection must NOT be empty

# âœ… TYPE AND CLASS ASSERTIONS
assert_kind_of Class, object          # Object must be instance of Class
assert_instance_of Class, object      # Object must be exact instance of Class
assert_respond_to object, :method     # Object must respond to method

# âœ… EXCEPTION ASSERTIONS
assert_raises(ExceptionClass) { code } # Code must raise specific exception
assert_nothing_raised { code }         # Code must not raise any exception

# âœ… EXPLICIT FAILURE
flunk "reason for failure"            # Explicit test failure with message
```

### **Hugo-Specific Test Integration**

The project's existing test structure supports both Ruby tests and Hugo validation:

```bash
# Ruby test structure (validated by bin/test)
test/
â”œâ”€â”€ unit/                    # Unit tests with proper assertions
â”‚   â”œâ”€â”€ about_page_quick_test.rb
â”‚   â”œâ”€â”€ seo_schema_test.rb
â”‚   â””â”€â”€ meta_tags_test.rb
â”œâ”€â”€ system/                  # System tests with browser validation
â”‚   â”œâ”€â”€ desktop_site_test.rb
â”‚   â””â”€â”€ mobile_site_test.rb
â””â”€â”€ support/                 # Test helpers and utilities
    â”œâ”€â”€ hugo_helpers.rb
    â””â”€â”€ hugo_memory_server.rb

# Hugo build validation (existing tools)
bun run build               # Standard Hugo build
bun run test:build          # Production rendering with diagnostics
bin/test                   # Full Ruby test suite
```

### **Test Quality Validation Examples**

Using existing project patterns from `test/unit/about_page_quick_test.rb`:

```ruby
# âœ… CORRECT: File existence validation
def test_about_page_template_exists
  about_template = File.join(Dir.pwd, "themes", "beaver", "layouts", "page", "about.html")
  assert File.exist?(about_template), "About page template should exist"
end

# âœ… CORRECT: Content validation with assertions
def test_about_template_has_required_sections
  template_content = File.read(about_template)

  assert_includes template_content, 'id="team-expertise"', "Template should have team-expertise section"
  assert_includes template_content, 'id="authority-signals"', "Template should have authority-signals section"
  assert_includes template_content, 'id="achievements"', "Template should have achievements section"
end

# âœ… CORRECT: Quantitative validation
def test_about_template_has_required_classes
  template_content = File.read(about_template)

  hover_box_count = template_content.scan(/hover-box/).length
  service_box_count = template_content.scan(/jt-service-box/).length

  assert hover_box_count >= 3, "Template should have at least 3 hover-box references, found #{hover_box_count}"
  assert service_box_count >= 3, "Template should have at least 3 jt-service-box references, found #{service_box_count}"
end
```

### **Agent Test Writing Workflow**

**Step 1**: Write failing test first (TDD Law 1)
```bash
# Create test file following naming convention
touch test/unit/new_feature_test.rb
```

**Step 2**: Run test to confirm it fails (TDD Law 2)
```bash
bin/test test/unit/new_feature_test.rb  # Should fail
```

**Step 3**: Write minimal code to pass test (TDD Law 3)
```bash
# Implement just enough to make test pass
bin/test test/unit/new_feature_test.rb  # Should pass
```

**Step 4**: Refactor while maintaining tests
```bash
# All tests must continue to pass
bin/test  # Full suite validation
```

## ğŸš€ **DEBUG BUILD INTEGRATION (Enhanced Validation)**

### **Production Rendering Verification with test:build**

The `bun run test:build` command provides comprehensive production rendering verification that catches issues missed by regular builds:

**Debug Build Features:**
- **Template Metrics**: Performance analysis of Hugo templates
- **Memory Usage Monitoring**: Real-time memory consumption tracking
- **Cache Validation**: Ignores cache to detect cache-related issues
- **Path Warnings**: Identifies broken internal links and resources
- **I18n Validation**: Internationalization configuration checks
- **Production Environment**: Full production simulation

### **Enhanced Validation Pipeline**

```bash
# Comprehensive validation integrating debug build
run_enhanced_tdd_validation() {
    echo "ğŸ” Enhanced TDD Validation with Debug Build Integration"

    # Stage 1: Debug Build Validation (catches cache & template issues)
    echo "ğŸ“Š Stage 1: Production Rendering Verification"
    if bun run test:build; then
        echo "âœ… DEBUG BUILD: Production rendering verified"
        extract_template_metrics
        validate_memory_usage
    else
        echo "âŒ DEBUG BUILD: CRITICAL FAILURE - Production rendering issues"
        return 1
    fi

    # Stage 2: Content TDD Validation
    echo "ğŸ“ Stage 2: Content Quality Validation"
    for content_file in content/blog/*/index.md; do
        if ! run_content_tdd_tests "$content_file"; then
            echo "âŒ CONTENT TDD: $content_file validation failed"
            return 1
        fi
    done

    # Stage 3: System Integration Tests
    echo "ğŸ§ª Stage 3: System Integration Tests"
    if ! bundle exec rake test; then
        echo "âŒ SYSTEM TESTS: Integration test failures"
        return 1
    fi

    echo "âœ… VALIDATION COMPLETE: All stages passed - Zero defects confirmed"
}

# Extract and validate template performance metrics
extract_template_metrics() {
    echo "ğŸ“Š Analyzing template performance metrics..."

    # Template metrics are output during debug build
    # Parse for performance bottlenecks
    local slow_templates=$(grep -E "(slow|warning)" hugo-debug.log 2>/dev/null || echo "")

    if [[ -n "$slow_templates" ]]; then
        echo "âš ï¸  PERFORMANCE WARNING: Slow templates detected"
        echo "$slow_templates"
        # Non-blocking - log for optimization but don't fail
    else
        echo "âœ… TEMPLATE PERFORMANCE: All templates within acceptable limits"
    fi
}

# Validate memory usage patterns
validate_memory_usage() {
    echo "ğŸ’¾ Validating memory usage patterns..."

    # Memory usage is logged during debug build
    local memory_warnings=$(grep -i "memory" hugo-debug.log 2>/dev/null || echo "")

    if [[ -n "$memory_warnings" ]]; then
        echo "âš ï¸  MEMORY WARNING: High memory usage detected"
        echo "$memory_warnings"
        # Monitor but don't fail unless critical
    else
        echo "âœ… MEMORY USAGE: Within normal parameters"
    fi
}
```

### **Build Type Selection Matrix**

| Scenario | Regular Build | Debug Build | Rationale |
|----------|---------------|-------------|-----------|
| **Development** | âœ… Primary | âŒ Too slow | Speed for rapid iteration |
| **Pre-commit** | âŒ Insufficient | âœ… Required | Comprehensive validation |
| **CI/CD Pipeline** | âœ… Fast check | âœ… Full validation | Both speed and thoroughness |
| **Production Deploy** | âŒ Risky | âœ… Final verification | Zero-defect deployment |
| **Content Creation** | âœ… Quick preview | âŒ Overkill | Content iteration speed |
| **Template Changes** | âŒ Insufficient | âœ… Critical | Template complexity validation |
| **Performance Audit** | âŒ No metrics | âœ… Required | Template performance analysis |

### **Error Detection Enhancement**

Debug build provides enhanced error detection:

```bash
# Enhanced error detection using debug output
detect_production_issues() {
    local debug_log="hugo-debug.log"
    local errors=0

    echo "ğŸ” Analyzing debug output for production issues..."

    # Check for template errors
    if grep -q "template.*error\|failed to render" "$debug_log" 2>/dev/null; then
        echo "âŒ TEMPLATE ERRORS: Critical template rendering failures"
        ((errors++))
    fi

    # Check for missing resources
    if grep -q "not found\|missing\|404" "$debug_log" 2>/dev/null; then
        echo "âŒ RESOURCE ERRORS: Missing files or broken references"
        ((errors++))
    fi

    # Check for performance warnings
    if grep -q "slow\|timeout\|memory.*high" "$debug_log" 2>/dev/null; then
        echo "âš ï¸  PERFORMANCE WARNINGS: Optimization opportunities detected"
        # Non-blocking for performance warnings
    fi

    if [[ $errors -eq 0 ]]; then
        echo "âœ… ERROR DETECTION: No critical issues found"
        return 0
    else
        echo "âŒ ERROR DETECTION: $errors critical issue(s) detected"
        return 1
    fi
}
```

## ğŸ“‹ **Test-Driven Development for Content Validation**

### **TDD Philosophy for Content Creation**
Apply test-driven development principles to content creation, ensuring every piece of content meets predefined quality criteria before publication:

1. **Write Tests First**: Define validation criteria before creating content
2. **Red-Green-Refactor**: Content fails â†’ Fix content â†’ Optimize
3. **Continuous Validation**: Every change triggers automatic validation
4. **Zero-Defect Delivery**: No content published without passing all tests

## ğŸ”´ **RED PHASE: Test-First Content Validation**

### **Pre-Content Creation Tests**
```bash
# Create validation test before writing content
create_content_tests() {
    local content_path=$1
    local test_file="${content_path%.*}.test.yaml"

    cat > "$test_file" << EOF
content_requirements:
  frontmatter:
    required_fields: [title, description, created_at, cover_image]
    title_length: [30, 70]
    description_length: [120, 180]
    tags_minimum: 3

  images:
    cover_image_required: true
    alt_text_quality: true
    file_size_max_kb: 500
    formats_allowed: [jpg, jpeg, png, webp]

  links:
    internal_links_valid: true
    external_links_reachable: true
    no_placeholder_links: true

  content_quality:
    no_placeholders: true
    heading_hierarchy_valid: true
    code_blocks_with_language: true
    min_word_count: 300

  seo:
    meta_description_present: true
    structured_data_valid: true
    canonical_url_set: true
    social_media_tags: true
EOF

    echo "âœ… Content tests created: $test_file"
}
```

### **Hugo Build Validation Tests**
```bash
# TDD build validation with comprehensive diagnostics
run_hugo_build_tdd_tests() {
    local content_dir=${1:-"content/"}
    local errors=0

    echo "ğŸ” Running Hugo Build TDD validation tests"

    # 1. Standard build test
    if ! bun run build >/dev/null 2>&1; then
        echo "ğŸ”´ FAIL: Hugo standard build"
        ((errors++))
    else
        echo "ğŸŸ¢ PASS: Hugo standard build"
    fi

    # 2. Debug build test with comprehensive diagnostics
    echo "ğŸ” Running production rendering validation with full diagnostics..."
    if ! bun run test:build 2>&1 | tee /tmp/hugo-debug.log; then
        echo "ğŸ”´ FAIL: Hugo debug build validation"
        echo "ğŸ“‹ Debug build provides:"
        echo "   â€¢ Production environment rendering verification"
        echo "   â€¢ Template metrics and performance analysis"
        echo "   â€¢ Memory usage tracking and optimization hints"
        echo "   â€¢ Cache bypassing to detect cache-related issues"
        echo "   â€¢ Path warnings and unused template detection"
        ((errors++))
    else
        echo "ğŸŸ¢ PASS: Hugo debug build validation"

        # Extract key metrics from debug output
        if grep -q "Template execution" /tmp/hugo-debug.log; then
            echo "ğŸ“Š Template metrics available in debug output"
        fi

        if grep -q "Memory usage" /tmp/hugo-debug.log; then
            echo "ğŸ’¾ Memory usage tracking captured"
        fi
    fi

    # 3. Link validation test
    if ! bun run test:links >/dev/null 2>&1; then
        echo "ğŸ”´ FAIL: Link validation"
        ((errors++))
    else
        echo "ğŸŸ¢ PASS: Link validation"
    fi

    return $errors
}
```

### **Validation Test Suite**
```bash
# TDD validation test runner
run_content_tdd_tests() {
    local content_file=$1
    local test_file="${content_file%.*}.test.yaml"
    local errors=0

    if [[ ! -f "$test_file" ]]; then
        echo "ğŸ”´ RED: No test file found - create tests first!"
        return 1
    fi

    echo "ğŸ” Running TDD validation tests for: $(basename "$content_file")"

    # Frontmatter validation tests
    if ! validate_frontmatter_tdd "$content_file" "$test_file"; then
        echo "ğŸ”´ FAIL: Frontmatter validation"
        ((errors++))
    else
        echo "ğŸŸ¢ PASS: Frontmatter validation"
    fi

    # Image validation tests
    if ! validate_images_tdd "$content_file" "$test_file"; then
        echo "ğŸ”´ FAIL: Image validation"
        ((errors++))
    else
        echo "ğŸŸ¢ PASS: Image validation"
    fi

    # Link validation tests
    if ! validate_links_tdd "$content_file" "$test_file"; then
        echo "ğŸ”´ FAIL: Link validation"
        ((errors++))
    else
        echo "ğŸŸ¢ PASS: Link validation"
    fi

    # Content quality tests
    if ! validate_content_quality_tdd "$content_file" "$test_file"; then
        echo "ğŸ”´ FAIL: Content quality validation"
        ((errors++))
    else
        echo "ğŸŸ¢ PASS: Content quality validation"
    fi

    # SEO tests
    if ! validate_seo_tdd "$content_file" "$test_file"; then
        echo "ğŸ”´ FAIL: SEO validation"
        ((errors++))
    else
        echo "ğŸŸ¢ PASS: SEO validation"
    fi

    if [[ $errors -eq 0 ]]; then
        echo "ğŸŸ¢ GREEN: All TDD tests passed!"
        return 0
    else
        echo "ğŸ”´ RED: $errors test(s) failed - fix content and re-run"
        return 1
    fi
}
```

## ğŸŸ¢ **GREEN PHASE: Content Implementation and Validation**

### **Content Creation Workflow**
```bash
# TDD content creation workflow
tdd_content_workflow() {
    local content_path=$1
    local content_title="$2"

    echo "ğŸ”„ Starting TDD content creation workflow"

    # 1. RED: Create tests first
    create_content_tests "$content_path"

    # 2. RED: Run tests (should fail - no content yet)
    if run_content_tdd_tests "$content_path"; then
        echo "âš ï¸  WARNING: Tests passed without content - check test configuration"
    else
        echo "ğŸ”´ RED: Tests correctly failing - ready to create content"
    fi

    # 3. GREEN: Create minimal viable content
    create_minimal_content "$content_path" "$content_title"

    # 4. GREEN: Run tests until they pass
    local attempt=1
    while ! run_content_tdd_tests "$content_path"; do
        echo "ğŸ”„ Attempt $attempt: Fixing content to pass tests..."
        # Interactive or automated content fixing
        ((attempt++))

        if [[ $attempt -gt 5 ]]; then
            echo "ğŸ”´ BLOCKING: Cannot fix content after 5 attempts"
            return 1
        fi
    done

    echo "ğŸŸ¢ GREEN: Content successfully passes all TDD tests!"
}

create_minimal_content() {
    local content_path=$1
    local title="$2"

    cat > "$content_path" << EOF
---
title: "$title"
description: "Minimal description for $title to pass initial validation tests"
created_at: "$(date -Iseconds)"
cover_image: "cover.jpg"
tags: ["development", "content", "tdd"]
draft: true
---

# $title

This is minimal content to pass TDD validation tests.

## Introduction

Content will be expanded during the refactor phase.

## Conclusion

Initial implementation complete - ready for refactoring phase.
EOF
}
```

### **Continuous Validation Loop**
```bash
# Watch mode for continuous TDD validation
watch_content_tdd() {
    local content_dir=${1:-"content/"}

    echo "ğŸ‘€ Starting TDD watch mode for: $content_dir"

    # Use fswatch if available, otherwise fallback to basic monitoring
    if command -v fswatch >/dev/null 2>&1; then
        fswatch -o "$content_dir" -e "\.md$" | while read f; do
            local changed_files=$(find "$content_dir" -name "*.md" -newer "$content_dir/.tdd_last_check" 2>/dev/null || find "$content_dir" -name "*.md")

            while IFS= read -r file; do
                if [[ -n "$file" ]]; then
                    echo "ğŸ”„ File changed: $(basename "$file")"
                    run_content_tdd_tests "$file"
                fi
            done <<< "$changed_files"

            touch "$content_dir/.tdd_last_check"
        done
    else
        echo "ğŸ“ Manual TDD mode - run validation after each change"
    fi
}
```

## ğŸ”µ **REFACTOR PHASE: Content and Process Optimization**

### **Micro-Refactoring for Content**
```bash
# Apply â‰¤3 line changes with validation
micro_refactor_content() {
    local content_file=$1
    local description="$2"

    echo "ğŸ”„ Micro-refactoring: $description"

    # 1. Backup current state
    cp "$content_file" "${content_file}.backup"

    # 2. Apply micro-change (â‰¤3 lines)
    echo "ğŸ“ Apply your â‰¤3 line changes now..."
    read -p "Press Enter when changes are complete..."

    # 3. Validate changes
    if run_content_tdd_tests "$content_file"; then
        echo "âœ… Micro-refactor successful"
        rm "${content_file}.backup"
    else
        echo "âŒ Micro-refactor broke tests - rolling back"
        mv "${content_file}.backup" "$content_file"
        return 1
    fi
}
```

### **Quality Metrics Dashboard**
```bash
# Generate TDD quality metrics
generate_tdd_metrics() {
    local content_dir=${1:-"content/"}
    local metrics_file="tdd_metrics.json"

    echo "ğŸ“Š Generating TDD quality metrics..."

    {
        echo "{"
        echo "  \"timestamp\": \"$(date -Iseconds)\","
        echo "  \"content_stats\": {"

        local total_files=$(find "$content_dir" -name "*.md" | wc -l)
        local test_coverage=$(find "$content_dir" -name "*.test.yaml" | wc -l)
        local passing_tests=0
        local failing_tests=0

        while IFS= read -r file; do
            if [[ -n "$file" ]]; then
                if run_content_tdd_tests "$file" >/dev/null 2>&1; then
                    ((passing_tests++))
                else
                    ((failing_tests++))
                fi
            fi
        done < <(find "$content_dir" -name "*.md")

        echo "    \"total_files\": $total_files,"
        echo "    \"test_coverage\": $test_coverage,"
        echo "    \"coverage_percentage\": $(( (test_coverage * 100) / total_files )),"
        echo "    \"passing_tests\": $passing_tests,"
        echo "    \"failing_tests\": $failing_tests,"
        echo "    \"pass_rate\": $(( (passing_tests * 100) / (passing_tests + failing_tests) ))"
        echo "  },"

        # Quality gate metrics
        echo "  \"quality_gates\": {"
        echo "    \"zero_defect_policy\": $([ $failing_tests -eq 0 ] && echo "true" || echo "false"),"
        echo "    \"tdd_compliance\": $([ $test_coverage -eq $total_files ] && echo "true" || echo "false"),"
        echo "    \"validation_automated\": true"
        echo "  }"
        echo "}"
    } > "$metrics_file"

    echo "ğŸ“ˆ Metrics saved to: $metrics_file"

    # Display summary
    echo ""
    echo "ğŸ“Š TDD QUALITY SUMMARY"
    echo "====================="
    echo "Total content files: $total_files"
    echo "Test coverage: $test_coverage/$total_files ($(( (test_coverage * 100) / total_files ))%)"
    echo "Passing tests: $passing_tests"
    echo "Failing tests: $failing_tests"
    echo "Pass rate: $(( (passing_tests * 100) / (passing_tests + failing_tests) ))%"

    if [[ $failing_tests -eq 0 ]]; then
        echo "âœ… ZERO-DEFECT POLICY: MAINTAINED"
    else
        echo "âŒ ZERO-DEFECT POLICY: VIOLATED - $failing_tests failures"
    fi
}
```

## ğŸ¯ **TDD Integration with Four-Eyes Principle**

### **Peer Review TDD Protocol**
```bash
# Four-eyes TDD validation
four_eyes_tdd_review() {
    local content_file=$1
    local reviewer_id="$2"
    local author_id="$3"

    echo "ğŸ‘¥ Four-Eyes TDD Review Process"

    # 1. Author runs TDD tests
    echo "ğŸ” Author ($author_id) validation:"
    if ! run_content_tdd_tests "$content_file"; then
        echo "âŒ BLOCKING: Author TDD validation failed"
        return 1
    fi

    # 2. Peer reviewer independently validates
    echo "ğŸ” Peer reviewer ($reviewer_id) validation:"
    if ! run_content_tdd_tests "$content_file"; then
        echo "âŒ BLOCKING: Peer TDD validation failed"
        return 1
    fi

    # 3. Store validation results in memory
    npx claude-flow@alpha hooks memory-store \
        --key "four-eyes/tdd-validation/$(basename "$content_file")" \
        --value "author:$author_id,reviewer:$reviewer_id,status:approved,timestamp:$(date -Iseconds)"

    echo "âœ… Four-Eyes TDD validation successful"
}
```

### **Quality Gate Enforcement**
```bash
# Pre-commit TDD quality gate
pre_commit_tdd_gate() {
    echo "ğŸš¨ TDD Quality Gate - Pre-Commit Validation"

    local changed_files=$(git diff --cached --name-only --diff-filter=ACM | grep '\.md$' || true)
    local gate_failures=0

    if [[ -z "$changed_files" ]]; then
        echo "â„¹ï¸  No markdown files changed - skipping TDD validation"
        return 0
    fi

    while IFS= read -r file; do
        if [[ -n "$file" && -f "$file" ]]; then
            echo "ğŸ” TDD validation for: $(basename "$file")"

            if ! run_content_tdd_tests "$file"; then
                echo "âŒ TDD quality gate FAILED for: $file"
                ((gate_failures++))
            else
                echo "âœ… TDD quality gate PASSED for: $file"
            fi
        fi
    done <<< "$changed_files"

    if [[ $gate_failures -gt 0 ]]; then
        echo ""
        echo "ğŸš¨ BLOCKING: $gate_failures file(s) failed TDD quality gates"
        echo "ğŸ“‹ Fix all TDD test failures before committing"
        echo "ğŸ”§ Run: bin/test to see detailed issues"
        return 1
    fi

    echo "âœ… All TDD quality gates PASSED - commit allowed"
    return 0
}
```

## ğŸ“ˆ **Success Metrics and KPIs**

### **TDD Quality Indicators**
- **Test Coverage**: 100% of content files have corresponding test files
- **Pass Rate**: >95% of content passes TDD validation
- **Defect Prevention**: Zero post-publication content issues
- **Cycle Time**: <30 minutes from content creation to publication approval

### **Continuous Improvement**
```bash
# Weekly TDD quality review
weekly_tdd_review() {
    echo "ğŸ“… Weekly TDD Quality Review - $(date '+%Y-%m-%d')"

    generate_tdd_metrics

    # Identify improvement opportunities
    echo "ğŸ¯ IMPROVEMENT OPPORTUNITIES:"
    echo "- Files without test coverage"
    echo "- Frequently failing validations"
    echo "- Slow validation bottlenecks"
    echo "- New validation requirements"

    # Update TDD standards based on findings
    echo "ğŸ“ TDD Standards Evolution:"
    echo "- Review and update test requirements"
    echo "- Enhance validation scripts"
    echo "- Optimize validation performance"
    echo "- Train team on new TDD practices"
}
```

## ğŸ”— **Integration Commands**

### **Git Hooks Setup**
```bash
# Install TDD pre-commit hook
install_tdd_hooks() {
    cat > .git/hooks/pre-commit << 'EOF'
#!/bin/bash
exec bin/test
EOF

    chmod +x .git/hooks/pre-commit
    echo "âœ… TDD pre-commit hook installed"
}
```

### **CI/CD Integration**
```bash
# TDD validation in CI pipeline
ci_tdd_validation() {
    echo "ğŸ”„ CI/CD TDD Validation Pipeline"

    # Run comprehensive TDD validation
    if ! bin/test; then
        echo "âŒ CI/CD FAILED: TDD validation errors"
        exit 1
    fi

    # Production rendering verification with debug diagnostics
    if ! bun run test:build; then
        echo "âŒ CI/CD FAILED: Production rendering validation failed"
        echo "ğŸ” Debug output includes:"
        echo "   â€¢ Template metrics and performance analysis"
        echo "   â€¢ Memory usage tracking"
        echo "   â€¢ Cache-related issue detection"
        echo "   â€¢ Path warnings and unused template alerts"
        exit 1
    fi

    # Generate and store metrics
    generate_tdd_metrics

    echo "âœ… CI/CD TDD validation successful"
}
```

---

**Remember**: TDD for content ensures zero-defect publication by catching issues early in the creation process, not after publication. Every piece of content must pass comprehensive TDD validation before reaching production.
