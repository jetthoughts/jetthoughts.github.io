# Data Collection Framework

## Survey Methodology Templates

### Quantitative Survey Design
```yaml
quantitative_framework:
  sampling_strategy:
    method: "Stratified random sampling"
    stratification_variables:
      - company_size: ["1-10", "11-50", "51-200", "201-1000", "1000+"]
      - industry: ["Technology", "Finance", "Healthcare", "E-commerce", "Other"]
      - role_level: ["Individual Contributor", "Team Lead", "Manager", "Director+"]
    
    sample_size_calculation:
      population_estimate: "Industry professional count"
      confidence_level: 95%
      margin_of_error: 5%
      minimum_sample: 384
      target_sample: 500
      oversampling_factor: 1.3
  
  question_design:
    scale_types:
      likert_5_point: "Strongly Disagree to Strongly Agree"
      satisfaction_5_point: "Very Unsatisfied to Very Satisfied"
      frequency_6_point: "Never, Rarely, Sometimes, Often, Very Often, Always"
      importance_4_point: "Not Important, Somewhat Important, Important, Very Important"
    
    question_ordering:
      - warm_up: "Easy demographic questions"
      - core_topics: "Main research questions"
      - sensitive_topics: "Salary, company-specific information"
      - cool_down: "Future predictions, optional feedback"
```

### Qualitative Interview Framework
```yaml
interview_methodology:
  participant_recruitment:
    screening_criteria:
      - relevant_experience: "Minimum 2 years in target role"
      - decision_authority: "Influence over technology decisions"
      - willingness: "Available for 45-60 minute interview"
      - diversity: "Geographic, company size, industry representation"
    
    recruitment_channels:
      - linkedin_outreach: "Direct messages to qualified profiles"
      - email_campaigns: "Newsletter subscribers and past survey participants"
      - referral_program: "Existing contacts and clients"
      - industry_events: "Conference networking and speaking engagements"
  
  interview_structure:
    pre_interview:
      - consent_recording: "Permission to record and transcribe"
      - confidentiality_agreement: "Data usage and anonymization"
      - context_setting: "Research goals and expected outcomes"
    
    during_interview:
      - rapport_building: "5-10 minutes of background discussion"
      - open_ended_exploration: "Tell me about your experience with..."
      - probing_questions: "Can you give me a specific example?"
      - clarification: "What I'm hearing is... is that correct?"
    
    post_interview:
      - key_points_summary: "Let me confirm the main themes"
      - additional_contacts: "Who else should I speak with?"
      - follow_up_permission: "Can I contact you for clarification?"
      - thank_you_process: "Appreciation and next steps"
```

## Data Visualization Guidelines

### Chart Selection Matrix
```yaml
visualization_guide:
  data_relationships:
    comparison:
      single_metric: "Bar charts for categorical comparisons"
      multiple_metrics: "Grouped bar charts or radar charts"
      time_series: "Line charts with trend analysis"
    
    distribution:
      continuous_data: "Histograms or box plots"
      categorical_data: "Pie charts (max 5 categories) or bar charts"
      geographic_data: "Choropleth maps or bubble maps"
    
    correlation:
      two_variables: "Scatter plots with correlation coefficient"
      multiple_variables: "Correlation matrices or parallel coordinates"
    
    composition:
      part_to_whole: "Stacked bar charts or treemaps"
      hierarchical: "Sunburst charts or treemaps"
      change_over_time: "Stacked area charts"
```

### Visual Design Standards
```yaml
design_system:
  color_palette:
    primary: "#2B5CE6"  # JetThoughts blue
    secondary: "#00D4AA"  # JetThoughts green
    neutral_scale: ["#F8F9FA", "#E9ECEF", "#6C757D", "#343A40"]
    semantic:
      success: "#28A745"
      warning: "#FFC107"
      danger: "#DC3545"
      info: "#17A2B8"
  
  typography:
    chart_titles: "Inter Bold, 18px"
    axis_labels: "Inter Medium, 14px"
    data_labels: "Inter Regular, 12px"
    annotations: "Inter Regular, 11px"
  
  accessibility:
    color_blindness: "Use patterns and textures in addition to color"
    contrast_ratio: "Minimum 4.5:1 for text elements"
    alternative_text: "Detailed alt text for all visualizations"
    keyboard_navigation: "Ensure all interactive elements are accessible"
```

### Interactive Dashboard Framework
```yaml
dashboard_components:
  filter_panel:
    demographics: "Company size, industry, location, experience"
    time_periods: "Year, quarter, custom date ranges"
    technology_focus: "Framework, language, platform filters"
    comparison_mode: "Side-by-side or overlay comparisons"
  
  main_visualizations:
    executive_summary: "Key metrics cards with trend indicators"
    primary_findings: "Main charts supporting research conclusions"
    detailed_breakdowns: "Drill-down capabilities for deeper analysis"
    geographic_analysis: "Interactive maps with hover details"
  
  data_quality_indicators:
    sample_sizes: "Show n-values for all statistics"
    confidence_intervals: "Display uncertainty where applicable"
    methodology_links: "Easy access to detailed methodology"
    data_freshness: "Last updated timestamps"
```

## Statistical Analysis Patterns

### Descriptive Statistics Template
```r
# R Statistical Analysis Template
library(tidyverse)
library(ggplot2)
library(corrplot)

# Data Quality Assessment
data_quality_check <- function(data) {
  list(
    completeness = sapply(data, function(x) sum(!is.na(x)) / length(x)),
    unique_values = sapply(data, function(x) length(unique(x))),
    outliers = sapply(data[sapply(data, is.numeric)], 
                     function(x) sum(abs(x - median(x, na.rm = TRUE)) > 2 * mad(x, na.rm = TRUE), na.rm = TRUE))
  )
}

# Descriptive Statistics
descriptive_stats <- function(data, group_var = NULL) {
  if (is.null(group_var)) {
    data %>%
      summarise_if(is.numeric, list(
        mean = ~mean(., na.rm = TRUE),
        median = ~median(., na.rm = TRUE),
        sd = ~sd(., na.rm = TRUE),
        q25 = ~quantile(., 0.25, na.rm = TRUE),
        q75 = ~quantile(., 0.75, na.rm = TRUE),
        n = ~sum(!is.na(.))
      ))
  } else {
    data %>%
      group_by(!!sym(group_var)) %>%
      summarise_if(is.numeric, list(
        mean = ~mean(., na.rm = TRUE),
        median = ~median(., na.rm = TRUE),
        sd = ~sd(., na.rm = TRUE),
        q25 = ~quantile(., 0.25, na.rm = TRUE),
        q75 = ~quantile(., 0.75, na.rm = TRUE),
        n = ~sum(!is.na(.))
      ), .groups = 'drop')
  }
}

# Statistical Significance Testing
significance_testing <- function(data, numeric_var, categorical_var) {
  if (length(unique(data[[categorical_var]])) == 2) {
    # Two-group comparison: t-test
    t_test_result <- t.test(data[[numeric_var]] ~ data[[categorical_var]])
    return(list(test = "t-test", p_value = t_test_result$p.value, 
                statistic = t_test_result$statistic))
  } else {
    # Multiple groups: ANOVA
    anova_result <- aov(data[[numeric_var]] ~ data[[categorical_var]])
    return(list(test = "ANOVA", p_value = summary(anova_result)[[1]]["Pr(>F)"][1,1],
                statistic = summary(anova_result)[[1]]["F value"][1,1]))
  }
}
```

### Correlation Analysis Framework
```python
# Python Statistical Analysis Template
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

class ResearchAnalyzer:
    def __init__(self, data):
        self.data = data
        self.numeric_columns = data.select_dtypes(include=[np.number]).columns
        self.categorical_columns = data.select_dtypes(include=['object']).columns
    
    def correlation_analysis(self, method='pearson'):
        """Comprehensive correlation analysis"""
        corr_matrix = self.data[self.numeric_columns].corr(method=method)
        
        # Find strong correlations (>0.7 or <-0.7)
        strong_correlations = []
        for i in range(len(corr_matrix.columns)):
            for j in range(i+1, len(corr_matrix.columns)):
                corr_value = corr_matrix.iloc[i, j]
                if abs(corr_value) > 0.7:
                    strong_correlations.append({
                        'var1': corr_matrix.columns[i],
                        'var2': corr_matrix.columns[j],
                        'correlation': corr_value
                    })
        
        return {
            'correlation_matrix': corr_matrix,
            'strong_correlations': pd.DataFrame(strong_correlations)
        }
    
    def segment_analysis(self, segment_column, target_columns):
        """Analyze differences across segments"""
        results = {}
        
        for target_col in target_columns:
            if target_col in self.numeric_columns:
                # ANOVA for numeric variables
                segments = [group[target_col].dropna() for name, group in self.data.groupby(segment_column)]
                f_stat, p_value = stats.f_oneway(*segments)
                
                results[target_col] = {
                    'test': 'ANOVA',
                    'f_statistic': f_stat,
                    'p_value': p_value,
                    'segment_means': self.data.groupby(segment_column)[target_col].mean()
                }
            else:
                # Chi-square for categorical variables
                contingency_table = pd.crosstab(self.data[segment_column], self.data[target_col])
                chi2, p_value, dof, expected = stats.chi2_contingency(contingency_table)
                
                results[target_col] = {
                    'test': 'Chi-square',
                    'chi2_statistic': chi2,
                    'p_value': p_value,
                    'contingency_table': contingency_table
                }
        
        return results
```

## Citation and Source Attribution

### Academic Citation Standards
```yaml
citation_framework:
  primary_sources:
    survey_data:
      format: "JetThoughts [Year] [Topic] Survey (n=[sample_size])"
      example: "JetThoughts 2024 Ruby Developer Salary Survey (n=847)"
      methodology_link: "Full methodology available at jetthoughts.com/research/methodology"
    
    interview_data:
      format: "JetThoughts [Year] [Topic] Interview Study ([n] participants)"
      example: "JetThoughts 2024 Fractional CTO Interview Study (23 participants)"
      anonymization: "All participants quoted anonymously unless explicit permission"
  
  secondary_sources:
    industry_reports:
      format: "Author/Organization (Year). Title. Publisher."
      example: "Stack Overflow (2024). Developer Survey Results. Stack Overflow."
      access_date: "Include retrieval date for online sources"
    
    academic_papers:
      format: "Author, A. B. (Year). Title of paper. Journal Name, Volume(Issue), pages."
      doi_inclusion: "Include DOI when available"
      peer_review_status: "Note if pre-print or peer-reviewed"
  
  data_attribution:
    third_party_data:
      permission: "Explicit permission required for substantial use"
      citation: "Clear attribution with source methodology"
      limitations: "Note any limitations or biases in original data"
    
    collaborative_data:
      co_branding: "Partner organization credit where applicable"
      contribution_clarity: "Clear delineation of each party's contribution"
      shared_methodology: "Unified methodology documentation"
```

### Source Credibility Framework
```yaml
source_evaluation:
  credibility_criteria:
    data_sources:
      tier_1: "Peer-reviewed academic publications, government statistics"
      tier_2: "Established industry organizations, reputable consulting firms"
      tier_3: "Trade publications, vendor-sponsored research"
      tier_4: "Blog posts, social media, unverified sources"
    
    evaluation_factors:
      methodology_transparency: "Is the data collection method clearly described?"
      sample_representativeness: "Does the sample represent the target population?"
      potential_bias: "Are there conflicts of interest or selection biases?"
      recency: "How current is the data relative to the research question?"
      reproducibility: "Can the results be verified or replicated?"
  
  source_documentation:
    bibliography_format: "APA style with full URLs and access dates"
    methodology_links: "Direct links to detailed methodology sections"
    data_availability: "Information about raw data availability"
    update_tracking: "Version control for evolving data sources"
```

### Quality Assurance Checklist
```yaml
quality_assurance:
  data_integrity:
    - completeness_check: "All required fields collected"
    - validation_rules: "Data within expected ranges and formats"
    - duplicate_detection: "Identification and handling of duplicate responses"
    - outlier_analysis: "Review of statistical outliers and extreme values"
  
  analysis_validity:
    - statistical_assumptions: "Verification of test assumptions"
    - multiple_testing_correction: "Adjustment for multiple comparisons"
    - effect_size_reporting: "Practical significance beyond statistical significance"
    - confidence_intervals: "Uncertainty quantification for estimates"
  
  reporting_standards:
    - transparent_methodology: "Detailed description of all analytical steps"
    - limitation_disclosure: "Clear statement of study limitations"
    - reproducible_analysis: "Code and data availability where possible"
    - peer_review: "Internal review by qualified team members"
```